{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import requests\n",
    "import json\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('mode.chained_assignment',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'authority': 'www.zillow.com',\n",
    "    'sec-ch-ua': '\"Google Chrome\";v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36',\n",
    "    'accept': '*/*',\n",
    "    'sec-fetch-site': 'same-origin',\n",
    "    'sec-fetch-mode': 'cors',\n",
    "    'sec-fetch-dest': 'empty',\n",
    "    'referer': 'https://www.zillow.com/co/?searchQueryState=%7B%22usersSearchTerm%22%3A%22CO%22%2C%22mapBounds%22%3A%7B%22west%22%3A-111.735869734375%2C%22east%22%3A-99.365264265625%2C%22south%22%3A36.269455423479094%2C%22north%22%3A41.67982549177817%7D%2C%22mapZoom%22%3A7%2C%22regionSelection%22%3A%5B%7B%22regionId%22%3A10%2C%22regionType%22%3A2%7D%5D%2C%22isMapVisible%22%3Atrue%2C%22filterState%22%3A%7B%22built%22%3A%7B%22max%22%3A2010%7D%2C%22att%22%3A%7B%22value%22%3A%22new%22%7D%2C%22ah%22%3A%7B%22value%22%3Atrue%7D%7D%2C%22isListVisible%22%3Atrue%7D',\n",
    "    'accept-language': 'en-US,en;q=0.9',\n",
    "}\n",
    "list1=['new','fresh%20paint','new%20premium','quartz','remodeled','renovated','shiplap','soft%20close','staging','stainless','turn%20key','updated']\n",
    "state='WA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-10eb6f68ae8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0msoup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'script'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'application/json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[0mdata1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'apiCache'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0ml1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for j in list1:\n",
    "    with requests.session() as s:\n",
    "        page = 1\n",
    "        end_page = 20\n",
    "        url = ''\n",
    "        url_list = []\n",
    "    \n",
    "        while page <= end_page:\n",
    "            url = 'https://www.zillow.com/co/4_p/?searchQueryState=%7B%22usersSearchTerm%22%3A%22'+state+'%22%2C%22mapBounds%22%3A%7B%22west%22%3A-111.735869734375%2C%22east%22%3A-99.365264265625%2C%22south%22%3A36.269455423479094%2C%22north%22%3A41.67982549177817%7D%2C%22mapZoom%22%3A7%2C%22regionSelection%22%3A%5B%7B%22regionId%22%3A10%2C%22regionType%22%3A2%7D%5D%2C%22isMapVisible%22%3Atrue%2C%22filterState%22%3A%7B%22built%22%3A%7B%22max%22%3A2010%7D%2C%22att%22%3A%7B%22value%22%3A%22'+j+'%22%7D%2C%22ah%22%3A%7B%22value%22%3Atrue%7D%7D%2C%22isListVisible%22%3Atrue%2C%22pagination%22%3A%7B%22currentPage%22%3A'+str(page)+'%7D%7D'\n",
    "            url_list.append(url)\n",
    "            page += 1\n",
    "    \n",
    "    request = ''\n",
    "    request_list = []\n",
    "    \n",
    "    for url in url_list:\n",
    "        request = s.get(url, headers=headers)\n",
    "        request_list.append(request)\n",
    "    \n",
    "    soup = ''\n",
    "    soup_list = []\n",
    "\n",
    "    for request in request_list:\n",
    "        soup = BeautifulSoup(request.content, 'lxml')\n",
    "        soup_list.append(soup)\n",
    "    df_list = []\n",
    "    for soup in soup_list:\n",
    "        df = pd.DataFrame()\n",
    "        for i in soup:\n",
    "            address = (soup.find_all (class_= 'list-card-addr'))\n",
    "            price = (soup.find_all (class_='list-card-price'))\n",
    "            beds = (soup.find_all(\"ul\", class_=\"list-card-details\"))\n",
    "            link = soup.find_all (class_= 'list-card-link')\n",
    "\n",
    "            df['prices'] = price\n",
    "            df['address'] = address\n",
    "            df['beds'] = beds\n",
    "            \n",
    "        urls = []\n",
    "        \n",
    "        for link in soup.find_all(\"article\"):\n",
    "            try:\n",
    "                href = link.find('a',class_=\"list-card-link\")['href']\n",
    "            except Exception as e:\n",
    "                href=''\n",
    "            #raise e \n",
    "\n",
    "            urls.append(href)\n",
    "        if '' in urls:\n",
    "            urls.remove('')\n",
    "        df['links'] = urls\n",
    "        df['links'] = df['links'].astype('str')\n",
    "        df_list.append(df)\n",
    "    df = pd.concat(df_list).reset_index().drop(columns='index')\n",
    "    df['address'] = df['address'].astype('str')\n",
    "    df['beds'] = df['beds'].astype('str')\n",
    "    df.loc[:,'address'] = df.loc[:,'address'].replace('<address class=\"list-card-addr\">', '', regex=True)\n",
    "\n",
    "    df.loc[:,'address'] = df.loc[:,'address'].replace('</address>', '', regex=True)\n",
    "    #df['prices'] = df['prices'].str.replace(r'\\D', '')\n",
    "\n",
    "    #filter unwanted property types\n",
    "    df = df[~df['beds'].str.contains(\"Land for sale\")]\n",
    "\n",
    "    #remove html tags from beds column\n",
    "    df.loc[:,'beds'] = df.loc[:,'beds'].replace('<ul class=\"list-card-details\"><li class=\"\">', ' ', regex=True)\n",
    "    df.loc[:,'beds'] = df.loc[:,'beds'].replace('<abbr class=\"list-card-label\"> <!-- -->bds</abbr></li><li class=\"\">', ' ', regex=True)\n",
    "    df.loc[:,'beds'] = df.loc[:,'beds'].replace('<abbr class=\"list-card-label\"> <!-- -->ba</abbr></li><li class=\"\">', ' ', regex=True)\n",
    "    df.loc[:,'beds'] = df.loc[:,'beds'].replace('<abbr class=\"list-card-label\"> <!-- -->bd</abbr></li><li class=\"\">', ' ', regex=True)\n",
    "    df.loc[:,'beds'] = df.loc[:,'beds'].replace('-<abbr class=\"list-card-label\"> <!-- -->Foreclosure</abbr>', '- Foreclosure', regex=True)\n",
    "    df.loc[:,'beds'] = df.loc[:,'beds'].replace('<abbr class=\"list-card-label\"> <!-- -->sqft</abbr></li><li class=\"list-card-statusText\">', ' ', regex=True)\n",
    "    df.loc[:,'beds'] = df.loc[:,'beds'].replace('<abbr class=\"list-card-label\"> <!-- -->acres lot</abbr></li><li class=\"list-card-statusText\">', ' ', regex=True)\n",
    "    df.loc[:,'beds'] = df.loc[:,'beds'].replace('</li></ul>', '', regex=True)\n",
    "    df.loc[:,'beds'] = df.loc[:,'beds'].replace('--', '0', regex=True)\n",
    "    df.loc[:,'beds'] = df.loc[:,'beds'].replace('Multi-family', 'Multifamily', regex=True)\n",
    "    df.loc[:,'beds'] = df.loc[:,'beds'].replace(' for sale', '', regex=True)\n",
    "    df.loc[:,'beds'] = df.loc[:,'beds'].replace('-<abbr class=\"list-card-label\"> <!0 0>Auction</abbr>', '- Auction', regex=True)\n",
    "    df.loc[:,'beds'] = df.loc[:,'beds'].replace('-<abbr class=\"list-card-label\"> <!0 0>Pending</abbr>', '- Pending', regex=True)\n",
    "    df[['beds','type']] = df.beds.apply(lambda x: pd.Series(str(x).split('-')))\n",
    "    df[['beds', 'baths', 'sq_feet']] = df.beds.str.split(expand=True)\n",
    "    df['prices']=df.prices.apply(lambda x: pd.Series(str(x).split('>')[1].split('<')[0]))\n",
    "    urls=df['links']\n",
    "    urls1=urls.tolist()\n",
    "    agent=[]\n",
    "    contact=[]\n",
    "    agentComp=[]\n",
    "    des=[]\n",
    "    for i in urls:\n",
    "        headers = {\n",
    "        'authority': 'www.zillow.com',\n",
    "        'sec-ch-ua': '\"Google Chrome\";v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"',\n",
    "        'sec-ch-ua-mobile': '?0',\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36',\n",
    "        'accept': '*/*',\n",
    "        'sec-fetch-site': 'same-origin',\n",
    "        'sec-fetch-mode': 'cors',\n",
    "        'sec-fetch-dest': 'empty',\n",
    "        'referer': i,\n",
    "        'accept-language': 'en-US,en;q=0.9',\n",
    "        }\n",
    "        response=requests.get(i,headers=headers)\n",
    "        soup=BeautifulSoup(response.content,'lxml')\n",
    "\n",
    "        data = json.loads(soup.find_all('script', type='application/json')[2].string)\n",
    "        data1=json.loads(data['apiCache'])\n",
    "        l1=list(data1.keys())\n",
    "        a=(str(l1[1]))\n",
    "        data2=data1[a]['property']['attributionInfo']\n",
    "        agent.append(data2['infoString4'])\n",
    "        contact.append(data2['infoString5'])\n",
    "        agentComp.append(data2['infoString6'])\n",
    "        des.append(data1[a]['property']['description'])\n",
    "    df['Listing Agent Name']=agent\n",
    "    df['Listing Agent Contact']=contact\n",
    "    df['Listing Agent Company']=agentComp\n",
    "    df['Description']=des\n",
    "    df['Key Word']=j\n",
    "    df.to_csv(state+'-'+j+'.csv')\n",
    "    print('done')\n",
    "            # <p data-testid=\"attribution-broker\" class=\"Text-c11n-8-62-4__sc-aiai24-0 bnmVPu\">Keller Williams Real Estate Services 818-432-3200</p>\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0507ca4863d74825e19143f64061a0d98fde3c42611721bd9ba5ee5b8cfcb010"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
